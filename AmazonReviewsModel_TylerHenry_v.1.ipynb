{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 13)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Amazon.csv')\n",
    "print(data.shape) #print the (rows,cols) of matrix\n",
    "#data.head(50) #print 1st 50 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features from Amazon.csv to add to feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add review length col to dataset (pandas)\n",
    "data['ReviewLen'] = data['Text'].str.len()\n",
    "\n",
    "# fix summary NaNs\n",
    "# fix Summary NaNs\n",
    "data.Summary = data.Summary.fillna(' ')\n",
    "\n",
    "# summary length\n",
    "data['SummaryLen'] = data.Summary.str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add cols for one and five star booleans\n",
    "data['FiveStars'] = 0 # set all rows to 0\n",
    "data['OneStar'] = 0\n",
    "\n",
    "# ix == if then\n",
    "data.ix[data['Score'] == 1, 'OneStar'] = 1 # if score is 1, set to 1\n",
    "data.ix[data['Score'] == 5, 'FiveStars'] = 1 # if score is 5, set to 1\n",
    "# maybe visualize the score distribution for helpful reviews\n",
    "\n",
    "# add col for avg stars of Product\n",
    "# data['AvgStars'] = data.groupby('ProductId')['Stars'].transform(lambda x: x.mean())\n",
    "# not sure how to do this, or if it's even useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert unix timestamp to datetime\n",
    "data['DateTime'] = pd.to_datetime(data['Time'], unit='s')\n",
    "# all these Times are midnight of a day\n",
    "\n",
    "# find day of week (0-6, Mon-Sun)\n",
    "data['DayOfWeek'] = data['DateTime'].dt.weekday\n",
    "data['Month'] = data['DateTime'].dt.month\n",
    "data['Year'] = data['DateTime'].dt.year\n",
    "\n",
    "# col for oldest review date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n reviews per product ID\n",
    "data['NReviewsProduct'] = data.groupby('ProductId')['ProductId'].transform('count')\n",
    "\n",
    "# # order of this review on item (first = 0, second = 1, etc.)\n",
    "# data['ReviewOrder'] = 0\n",
    "# # for each row\n",
    "# # group data by ProductId and then order by timestamp\n",
    "\n",
    "# # then save order to 'ReviewOrder'\n",
    "# productId_group = data.groupby('ProductId')\n",
    "\n",
    "\n",
    "# n reviews per user ID\n",
    "data['NReviewsUser'] = data.groupby('UserId')['UserId'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert score + reviewLen cols to vectors\n",
    "# [:, 7] denotes all rows in col 7\n",
    "\n",
    "XScore = data.Score.values.reshape(data.shape[0], 1)\n",
    "XTime = data.Time.values.reshape(data.shape[0], 1)\n",
    "XReviewLen = data.ReviewLen.values.reshape(data.shape[0], 1)\n",
    "XSummaryLen = data.SummaryLen.values.reshape(data.shape[0], 1)\n",
    "XFiveStars = data.FiveStars.values.reshape(data.shape[0], 1)\n",
    "XOneStar = data.OneStar.values.reshape(data.shape[0], 1)\n",
    "XDayOfWeek = data.DayOfWeek.values.reshape(data.shape[0], 1)\n",
    "XMonth = data.Month.values.reshape(data.shape[0], 1)\n",
    "XYear = data.Year.values.reshape(data.shape[0], 1)\n",
    "XNReviewsProduct = data.NReviewsProduct.values.reshape(data.shape[0], 1)\n",
    "XNReviewsUser = data.NReviewsUser.values.reshape(data.shape[0], 1)\n",
    "\n",
    "# concatenate to numpy dataset\n",
    "XToAdd = np.concatenate((XScore, XOneStar, XFiveStars, XTime, XReviewLen, XDayOfWeek, XMonth, XYear, XNReviewsProduct, XNReviewsUser), axis=1)\n",
    "\n",
    "XToAdd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# Text\n",
    "hvText = HashingVectorizer(stop_words='english', n_features=2 ** 17, non_negative=True)\n",
    "XText = hvText.transform(data.Text)\n",
    "# Summary\n",
    "hvSummary = HashingVectorizer(stop_words='english', n_features=2 ** 17, non_negative=True)\n",
    "XSummary = hvSummary.transform(data.Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tf-idf transformer with pipeline from hash vectorizer?\n",
    "#### example ####\n",
    "# hashing = HashingVectorizer(non_negative=True, norm=None)\n",
    "# tfidf = TfidfTransformer()\n",
    "# hashing_tfidf = Pipeline([(\"hashing\", hashing), (\"tidf\", tfidf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XToAddSparse = csr_matrix(XToAdd)\n",
    "XFinal = hstack([XText, XToAddSparse])\n",
    "X = csr_matrix(XFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 131082)\n"
     ]
    }
   ],
   "source": [
    "# size of feature set\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = data.helpful.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "def print_results():\n",
    "    print('Error rate on training set: ')\n",
    "    print((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('Accuracy rate on training set: ')\n",
    "    print(1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('True positive rate on training set:')\n",
    "    print(((y_train==True) & (y_pred==True)).sum() / y_train.sum())\n",
    "    print('**************')\n",
    "    print('Error rate on test set: ')\n",
    "    print((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('Accuracy rate on test set: ')\n",
    "    print(1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('True positive rate on test set')\n",
    "    print(((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    print('True negative rate on test set')\n",
    "    print(((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0720031397174\n",
      "Accuracy rate on training set: \n",
      "0.927996860283\n",
      "True positive rate on training set:\n",
      "0.0127001894266\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0741025641026\n",
      "Accuracy rate on test set: \n",
      "0.925897435897\n",
      "True positive rate on test set\n",
      "0.00559608274208\n",
      "True negative rate on test set\n",
      "0.998703485568\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0468477237049\n",
      "Accuracy rate on training set: \n",
      "0.953152276295\n",
      "True positive rate on training set:\n",
      "0.372825899776\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0729010989011\n",
      "Accuracy rate on test set: \n",
      "0.927098901099\n",
      "True positive rate on test set\n",
      "0.164384930549\n",
      "True negative rate on test set\n",
      "0.98743804005\n"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.108150706436\n",
      "Accuracy rate on training set: \n",
      "0.891849293564\n",
      "True positive rate on training set:\n",
      "0.581496469778\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.148666666667\n",
      "Accuracy rate on test set: \n",
      "0.851333333333\n",
      "True positive rate on test set\n",
      "0.323773358649\n",
      "True negative rate on test set\n",
      "0.893069181694\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.0564615384615\n",
      "Accuracy rate on training set: \n",
      "0.943538461538\n",
      "True positive rate on training set:\n",
      "0.424487687274\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.0837289377289\n",
      "Accuracy rate on test set: \n",
      "0.916271062271\n",
      "True positive rate on test set\n",
      "0.230338762866\n",
      "True negative rate on test set\n",
      "0.970535918984\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
